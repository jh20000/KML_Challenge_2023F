# 🏆 KML Challenge 2023F - 온라인 설문조사 응답 예측

## 📌 프로젝트 개요
Kaggle KML Challenge 2023F 대회에서는 **"각 패널에게 어떤 온라인 설문조사를 요청해야 응답할까?"**라는 문제를 해결하는 것이 목표였습니다.  
즉, 패널의 정보와 설문 데이터를 바탕으로 **응답 여부(`STATUS`)를 예측하는 머신러닝 모델을 개발**하는 대회였습니다.

- **평가 척도:** Accuracy (정확도)
- **데이터 구성:**  
  - `train.csv` (813,650개) - 학습 데이터  
  - `test.csv` (541,867개) - 평가 데이터  
  - 총 44개의 컬럼(패널 정보, 설문 정보, 응답 여부 포함)  

---

## 데이터 전처리 & Feature Engineering

### 🛠 1. 데이터 전처리
- **결측치 처리:**  
  - 범주형 변수 → 최빈값(`mode`)으로 대체  
  - 수치형 변수 → 평균값(`mean`)으로 대체  
- **피처 정리:**  
  - 결측치 비율이 30% 이상인 컬럼 제거  
  - 일부 피처에서 불필요한 공백(`,` 포함)으로 인해 같은 값이 다르게 분류되는 문제 해결  

### 🏗 2. Feature Engineering
**모델 성능을 높이기 위해 다양한 피처를 추가했습니다.**  

1️⃣ **응답률 관련 피처**
   - 패널별 응답률 (`RES_RATE_user`)
   - 패널 타입별 응답률 (`RES_RATE_type`)
   - 설문별 응답률 (`RES_RATE_survey`)  
   → 너무 세밀한 수치는 모델 학습을 복잡하게 만들기 때문에 소수점 3자리까지 반올림한 값 사용

2️⃣ **설문 정보 관련 피처**
   - 설문 제목(`TITLE`)에서 주요 단어(해외, 소비자, 일반인 등) 포함 여부를 피처로 추가  
   - 제목에서 등장하는 단어 빈도를 기반으로 Encoding  

3️⃣ **리워드 & 설문 시간 관련 피처**
   - `리워드 / 응답 시간` → 리워드가 많을수록 응답 가능성이 높다고 가정  
   - `-(설문 시간 + 난이도)` → 시간이 길수록 응답 가능성이 낮다고 가정  

4️⃣ **패널별 성향 반영**
   - 패널별 총 응답 횟수 (`Status_sum_log`) → 로그 변환하여 정규화  
   - 응답한 사용자별 평균 획득 포인트를 구간화하여 피처 추가  

### 📏 3. 데이터 변환
- **수치형 피처:** StandardScaler 적용  
- **범주형 피처:** Ordinal Encoding 적용  

---

## 🚀 Feature Selection
- SHAP(Shapley Additive Explanations) 라이브러리를 사용하여 **각 피처의 중요도를 분석**  
- 중요도가 낮은 피처를 제거하고, 성능이 향상되는 피처를 추가하여 최적의 Feature Selection 진행  

---

## 🏗 Model Building & Evaluation

### 🤖 실험한 모델들
- 처음에는 **DecisionTree, RandomForest, Ridge, Lasso, BaggingClassifier** 등 다양한 모델을 테스트했지만,  
  결국 **LightGBM, CatBoost, XGBoost**가 가장 좋은 성능을 보였습니다.

### 🔄 교차검증을 활용한 OOF 앙상블
모델의 일반화 성능을 높이기 위해 **OOF(Out-of-Fold) 방식으로 5-Fold 교차검증을 적용**했습니다.

- **5개의 폴드를 생성하여 각각 학습**  
- **폴드별 예측값을 Soft Voting(예측값 평균) 방식으로 앙상블**  
- **임계값(`threshold`) 0.495 설정** (실험을 통해 최적값 도출)  
- **최종적으로 Hard Voting (다수결 방식) 적용하여 최종 예측값 생성**  

### 🔀 추가적인 앙상블
마지막으로, **전체 피처를 변환하여 학습한 모델들을 보팅 앙상블**을 진행했습니다.

- **로그 변환 (`log1p`)**
- **제곱근 변환 (`sqrt`)**
- **MinMax 정규화 적용**  
  → 변환된 데이터를 기반으로 개별 모델을 학습하고, Soft Voting을 수행하여 최종 결과 도출  

---

## 📈 프로젝트 진행 과정
1️⃣ **EDA(탐색적 데이터 분석)**  
   - 데이터 분포, 결측치 처리, 피처 분포 확인 및 정리  

2️⃣ **Feature Engineering**  
   - 응답률, 설문 제목, 리워드, 시간 등 다양한 피처 생성  
   - SHAP을 활용한 Feature Selection  

3️⃣ **모델 학습 및 최적화**  
   - OOF 방식으로 5-Fold 학습 진행  
   - Soft Voting, Hard Voting 적용  
   - 데이터 변환 후 추가적인 앙상블 수행  

4️⃣ **결과 분석 & 제출**  
   - 모델 성능 비교 및 최적 모델 선정  
   - Kaggle 제출 후 성능 분석  

---

## 🎯 최종 정리
✔ **패널별, 설문별 응답률을 기반으로 피처를 생성**  
✔ **LightGBM, CatBoost, XGBoost 모델을 활용한 OOF 방식 5-Fold Soft Voting 적용**  
✔ **Hard Voting & 데이터 변환 후 추가적인 앙상블 기법을 적용하여 성능 최적화**  

 **프로젝트를 진행하면서 가장 중요했던 점은 다양한 피처를 실험하고 최적화하는 과정이었어요.**  
 **특히 이번 프로젝트의 경우 데이터가 많기 때문에 피처생성이 중요했던 것 같습니다.
 ** 피처또한 과적합되는 피처를 생성했을 때가 정말 많았는데 그것이 왜 과적합되는지 분석하는 과정이 정말 어려웠습니다.
 
📢 **코드 및 상세 분석 과정은 [노트북 링크]에서 확인할 수 있습니다.**  
